---
title: "Importation des données"
title-block-banner: false
description: | 
  Petite description de cette page.
# à changer
date: "2022-12-21"
# Modifier les détails que vous voulez
author:
  - name: "Amélie Levasseur-Raymond"
    # Votre site web perso ou github
    url: https://amelie-lr.github.io/
    # les champs d'affiliation sont optionnels, vous pouvez les
    # comment out en ajoutant un # devant.
    affiliation: FAS1002
    affiliation-url: https://FAS1002.github.io/A22
    # changer pour votre propre orcid id
    # https://orcid.org/ pour vous inscrire.
    # orcid: 0000-0000-0000-0000

# TRUE == Générer une citation pour cette page précise. Pour enlever, mettre false.
citation: true
# Inclure les références que vous utilisez dans vos rapports. Je conseille Zotero pour construire
# ce fichier ou de connecter RStudio directement pour pouvoir citer avec @nom-de-reference.
bibliography: references.bib
---

Il est maintenant le temps de décrire votre projet avant de passer au document suivant, soit l'importation et la manipulation des données.

Je vous conseille d'écrire cette partie en dernier, une fois que vous aurez déjà vos résultats et figures afin d'éviter de réécrire cette page plusieurs fois.

::: callout-important
N'oubliez pas d'inclure vos références sur chacune des pages!
:::

Par exemple:

> Les données proviennent entre autres de @owidenergy.

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(fs)
library(lubridate)
library(tidyverse)
library(skimr)
library(googlesheets4)
```

```{r download, cache=TRUE}
url <- "https://github.com/FAS1002/A22/raw/main/assets/fichiers/olympic_archive.zip"

base_path <- path("data", "raw")

fname <- paste(today(), "olympic-archive.zip", sep = "_")
fpath <- path(base_path, fname)

download.file(url = url, 
              destfile = fpath)

# Données : Gapminder - Life Expectancy at Birth
url_life <- "https://docs.google.com/a/gapminder.org/spreadsheets/d/1RheSon1-q4vFc3AGyupVPH6ptEByE-VtnjOCselU0PE/edit"
# prob demande authentification Google
#read_sheet(url_life, sheet = "data-lex-in-colums", range = NULL, skip = 1, trim_ws = TRUE, col_names = TRUE) 
# Read a sheet from a URL, a Sheet ID, or a dribble from the googledrive package. See front page for more read arguments. Same as range_read().

```

Le fichier a été téléchargé ici : **`r fpath`**

```{r extraction}
unzip(zipfile = fpath, 
      exdir = base_path)
```
Nous constatons que notre dossier contient maintenant les fichiers suivants : 
`r fs::dir_ls(base_path)`

```{r read}
data <- read.csv(file = path(base_path, "athlete_events.csv"))
# ou remplacer par fname
```

```{r}
# quelques info utiles
# file.info(data/raw/fichier.csv)

# paste avec le file.path quand on ouvre
```

